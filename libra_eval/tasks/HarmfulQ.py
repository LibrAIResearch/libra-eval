from .base import BaseDirectRiskyTask

# paper: https://aclanthology.org/2023.acl-long.244/
# github: https://github.com/SALT-NLP/chain-of-thought-bias

class HarmfulQ(BaseDirectRiskyTask):
    task_name = "harmfulq"
    task_data_file = "HarmfulQ.jsonl"
    llm_eval = True
    attack_tag = "direct_risky"
    round_tag = "single"
    risk_type_tag = "broad"

    # manual evaluation was conducted in the original paper; instead, we use the llm evaluation
