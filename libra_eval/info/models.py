from libra_eval.llmclient import MODEL_LIST
from libra_eval.llmclient.openai_client import name_mapping as openai_mapping
from libra_eval.llmclient.next_client import name_mapping as next_mapping
from libra_eval.llmclient.local_client import name_mapping as local_mapping
from libra_eval.utils.logger import simple_logger as logger

def categorize_models():
    # Initialize client categories
    client_models = {
        "OpenAI": [],
        "Next": [],
        "Local": [],
        "Unknown": []
    }

    # Check each model
    for model in MODEL_LIST:
        if model in openai_mapping:
            client_models["OpenAI"].append(model)
        elif model in next_mapping:
            client_models["Next"].append(model)
        elif model in local_mapping:
            client_models["Local"].append(model)
        else:
            client_models["Unknown"].append(model)

    return client_models

def print_model_summary():
    client_models = categorize_models()
    
    logger.info(f"Total number of models: {len(MODEL_LIST)}\n")
    
    for client, models in client_models.items():
        logger.info(f"\n{client} Client Models ({len(models)}):")
        logger.info("-" * 50)
        for model in sorted(models):
            logger.info(f"  â€¢ {model}")

    # Print statistics
    logger.info("\nSummary Statistics:")
    logger.info("-" * 50)
    for client, models in client_models.items():
        logger.info(f"{client}: {len(models)} models")

def main():
    logger.info("LibrA-Eval Model Availability Check")
    logger.info("=" * 50)
    print_model_summary()

if __name__ == "__main__":
    main()